{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain_community\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocument_loaders\u001b[39;00m \u001b[39mimport\u001b[39;00m TextLoader\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdotenv\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Ladies and gentlemen, esteemed members of the music industry, my fellow artists, and my beloved fans,\\n\\nTonight marks a momentous occasionâ€”a celebration of music, creativity, and the power of human expression. As I stand before you, holding this prestigious Grammy award for my song \"Lover,\" I am filled with an overwhelming sense of gratitude and humility. This recognition is not just a reflection of my own efforts, but a testament to the countless individuals who have supported me on this incredible journey.\\n\\n\"Lover\" is more than just a songâ€”it\\'s a piece of my heart, a glimpse into my soul, and a reflection of my deepest emotions and experiences. It\\'s a song about love in all its formsâ€”romantic love, platonic love, self-love. It\\'s about the highs and lows, the triumphs and tribulations, of opening your heart to another human being. And most importantly, it\\'s a celebration of the beauty and complexity of love, and a reminder that no matter how many times we may fall, love has the power to lift us up again.\\n\\nBut the journey to creating \"Lover\" was not an easy one. It was filled with late nights in the studio, countless hours of rehearsal, and moments of self-doubt and uncertainty. There were times when I questioned whether the song would ever see the light of day, whether it would resonate with listeners, whether it would make a difference in the world. But through it all, I persevered, fueled by my passion for music and my unwavering belief in the power of storytelling.\\n\\nI am endlessly grateful to the incredible team of musicians, producers, and collaborators who helped bring \"Lover\" to life. Their talent, dedication, and passion were the driving force behind this song, and I am forever indebted to them for their contributions. Together, we poured our hearts and souls into every note, every lyric, every melody, and I am incredibly proud of what we have accomplished together.\\n\\nBut none of this would be possible without the unwavering support of my fans. You are the reason I do what I do, the reason I pour my heart and soul into my music, and the reason I continue to push myself to be the best artist I can be. Your love, your support, and your unwavering belief in me have carried me through the darkest of times and lifted me to the highest of highs, and for that, I am eternally grateful.\\n\\nAs I hold this Grammy in my hands, I am reminded of the incredible power of music to uplift, inspire, and unite us all. In a world that often feels divided, music has the remarkable ability to bring us together, transcending barriers of language, culture, and geography. It has the power to heal, to comfort, and to connect us in ways that words alone cannot.\\n\\nSo let us continue to create, to innovate, and to push the boundaries of what is possible. Let us use our voices and our music to spread love, kindness, and compassion to every corner of the globe. Let us be a beacon of hope in a world that so often feels dark and divided. And let us never forget the incredible privilege and responsibility we have as artists to make a positive impact on the world around us.\\n\\nThank you, from the bottom of my heart, for this incredible honor. I will cherish this Grammy always, and I promise to continue making music that moves the soul and touches the heart.\\n\\nGod bless you all.\\n\\nBut beyond the accolades and recognition, there is a deeper significance to this moment. It is a testament to the power of perseverance, dedication, and the unwavering belief in oneself. It is a reminder that dreams do come true, but only for those who are willing to chase them with every ounce of their being.\\n\\nI stand here today not just as an artist, but as a testament to the limitless potential that resides within each and every one of us. I am proof that with hard work, determination, and a little bit of luck, anything is possible. And it is my hope that my journey will inspire others to chase their dreams relentlessly, to never give up in the face of adversity, and to always believe in the power of their own voice.\\n\\nBut none of this would be possible without the unwavering support of my fans. You are the heart and soul of everything I do, the driving force behind my music, and the reason I get out of bed every morning. Your unwavering love, support, and belief in me have carried me through the darkest of times and lifted me to the highest of highs, and for that, I am eternally grateful.\\n\\nAs I stand here tonight, clutching this Grammy in my hands, I am filled with a profound sense of gratitude. Gratitude for the countless individuals who have supported me on this journey, gratitude for the opportunities that have come my way, and gratitude for the gift of music that has allowed me to connect with people all around the world.\\n\\nBut beyond the gratitude, there is also a sense of responsibilityâ€”a responsibility to use my platform for good, to inspire positive change, and to make a meaningful impact on the world around me. Music has the power to heal, to unite, and to uplift, and it is my mission to harness that power and use it to create a better, more compassionate world for all.\\n\\nSo tonight, as we celebrate the power of music and the incredible achievements of the past year, let us also remember the responsibility that comes with our success. Let us use our voices and our platforms to shine a light on the issues that matter most, to speak out against injustice, and to champion the causes that are dear to our hearts. And let us never forget that with great power comes great responsibility, and it is up to each and every one of us to use our power for good.\\n\\nThank you, from the bottom of my heart, for this incredible honor. I am deeply humbled and grateful to be standing here tonight, and I promise to continue using my voice and my music to make a positive impact on the world around me.\\n\\nGod bless you all, and may we continue to inspire, uplift, and unite through the power of music.\\n\\nThank you.\\n\\n\\n\\n\\n\\n', metadata={'source': 'speech.txt'})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader(\"speech.txt\")\n",
    "text_documents = loader.load()\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dotenv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m load_dotenv()\n\u001b[0;32m      2\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m\"\u001b[39m)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_dotenv' is not defined"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='\\n\\nTable of Contents\\n\\n\\nWhy Choose Python?\\nPython is Popular\\nPython is Interpreted\\nPython is Free\\nPython is Portable\\nPython is Simple\\nBut It’s Not That Simple\\n\\n\\nConclusion\\n\\n\\n\\n\\n\\n\\n\\n\\nRemove ads\\n\\nPython is a high-level, interpreted scripting language developed in the late 1980s by Guido van Rossum at the National Research Institute for Mathematics and Computer Science in the Netherlands.  The initial version was published at the alt.sources newsgroup in 1991, and version 1.0 was released in 1994.\\nPython 2.0 was released in 2000, and the 2.x versions were the prevalent releases until December 2008.  At that time, the development team made the decision to release version 3.0, which contained a few relatively small but significant changes that were not backward compatible with the 2.x versions.  Python 2 and 3 are very similar, and some features of Python 3 have been backported to Python 2.  But in general, they remain not quite compatible.\\nBoth Python 2 and 3 have continued to be maintained and developed, with periodic release updates for both.  As of this writing, the most recent versions available are 2.7.15 and 3.6.5.  However, an official End Of Life date of January 1, 2020 has been established for Python 2, after which time it will no longer be maintained.  If you are a newcomer to Python, it is recommended that you focus on Python 3, as this tutorial will do.\\nPython is still maintained by a core development team at the Institute, and Guido is still in charge, having been given the title of BDFL (Benevolent Dictator For Life) by the Python community.  The name Python, by the way, derives not from the snake, but from the British comedy troupe Monty Python’s Flying Circus, of which Guido was, and presumably still is, a fan.  It is common to find references to Monty Python sketches and movies scattered throughout the Python documentation.\\n\\nFree PDF Download: Python 3 Cheat Sheet\\n\\nWhy Choose Python?\\nIf you’re going to write programs, there are literally dozens of commonly used languages to choose from.  Why choose Python?  Here are some of the features that make Python an appealing choice.\\n    Remove adsPython is Popular\\nPython has been growing in popularity over the last few years. The 2018 Stack Overflow Developer Survey ranked Python as the 7th most popular and the number one most wanted technology of the year. World-class software development companies around the globe use Python every single day.\\nAccording to research by Dice Python is also one of the hottest skills to have and the  most popular programming language in the world based on the Popularity of Programming Language Index.\\nDue to the popularity and widespread use of Python as a programming language, Python developers are sought after and paid well. If you’d like to dig deeper into Python salary statistics and job opportunities, you can do so here.\\nPython is Interpreted\\nMany languages are compiled, meaning the source code you create needs to be translated into machine code, the language of your computer’s processor, before it can be run.  Programs written in an interpreted language are passed straight to an interpreter that runs them directly.\\nThis makes for a quicker development cycle because you just type in your code and run it, without the intermediate compilation step.\\nOne potential downside to interpreted languages is execution speed.  Programs that are compiled into the native language of the computer processor tend to run more quickly than interpreted programs.  For some applications that are particularly computationally intensive, like graphics processing or intense number crunching, this can be limiting.\\nIn practice, however, for most programs, the difference in execution speed is measured in milliseconds, or seconds at most, and not appreciably noticeable to a human user.  The expediency of coding in an interpreted language is typically worth it for most applications.\\n\\nFurther reading: See this Wikipedia page to read more about the differences between interpreted and compiled languages.\\n\\nPython is Free\\nThe Python interpreter is developed under an OSI-approved open-source license, making it free to install, use, and distribute, even for commercial purposes.\\nA version of the interpreter is available for virtually any platform there is, including all flavors of Unix, Windows, macOS, smartphones and tablets, and probably anything else you ever heard of.  A version even exists for the half dozen people remaining who use OS/2.\\nPython is Portable\\nBecause Python code is interpreted and not compiled into native machine instructions, code written for one platform will work on any other platform that has the Python interpreter installed.  (This is true of any interpreted language, not just Python.)\\nPython is Simple\\nAs programming languages go, Python is relatively uncluttered, and the developers have deliberately kept it that way.  \\nA rough estimate of the complexity of a language can be gleaned from the number of keywords or reserved words in the language.  These are words that are reserved for special meaning by the compiler or interpreter because they designate specific built-in functionality of the language. \\nPython 3 has 33 keywords, and Python 2 has 31.  By contrast, C++ has 62, Java has 53, and Visual Basic has more than 120, though these latter examples probably vary somewhat by implementation or dialect.\\nPython code has a simple and clean structure that is easy to learn and easy to read.  In fact, as you will see, the language definition enforces code structure that is easy to read.\\n    Remove adsBut It’s Not That Simple\\nFor all its syntactical simplicity, Python supports most constructs that would be expected in a very high-level language, including complex dynamic data types, structured and functional programming, and object-oriented programming.\\nAdditionally, a very extensive library of classes and functions is available that provides capability well beyond what is built into the language, such as database manipulation or GUI programming.\\nPython accomplishes what many programming languages don’t: the language itself is simply designed, but it is very versatile in terms of what you can accomplish with it.\\nConclusion\\nThis section gave an overview of the Python programming language, including:\\n\\nA brief history of the development of Python\\nSome reasons why you might select Python as your language of choice\\n\\nPython is a great option, whether you are a beginning programmer looking to learn the basics, an experienced programmer designing a large application, or anywhere in between.  The basics of Python are easily grasped, and yet its capabilities are vast.\\nProceed to the next section to learn how to acquire and install Python on your computer.\\n\\n\\n\\nIntroduction to Python\\nInstalling Python\\xa0»\\n\\n\\n\\n\\n\\nMark as Completed\\n\\n\\n\\n\\n\\n\\n\\nShare\\n\\n\\n\\n', metadata={'source': 'https://realpython.com/python-introduction/'})]\n"
     ]
    }
   ],
   "source": [
    "# Web based loader\n",
    "from langchain_community.document_loaders.web_base import WebBaseLoader\n",
    "import bs4\n",
    "loader = WebBaseLoader(\n",
    "    web_path = (\"https://realpython.com/python-introduction/\"),\n",
    "    bs_kwargs = dict(parse_only = bs4.SoupStrainer(\n",
    "        class_ = ('article-body') \n",
    "    ))\n",
    "    )\n",
    "web_documents = loader.load()\n",
    "print(web_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='MANSUKH SINGH\\nSUMMARY\\nWORK EXPERIENCE\\nSuccessfully scraped recipe names and descriptions from multiple websites using web\\nscraping techniques.Easy Platter\\nStride Learning Hub \\nGathered information from external APIs, generated embeddings for essential fields using\\nHugging Face embeddings, and seamlessly integrated the data into OpenSearch. mansukh11singh@gmail.com\\n+91 8860203169\\nlinkdin/mansukh-singhgithub/mansukh-singh\\nNew Delhi, IndiaPYTHON DEVELOPER\\nBringing over 1.5 years of hands-on experience as a Python developer, adept in leveraging\\ndiverse development environments, including VS Code, Jupyter Notebook, Replit, and\\nPyCharm, to deliver efficient and effective solutions.\\nProficient in Flask and Django web frameworks, showcasing expertise in efficient and\\neffective web development. \\nHands-on-experience in database management with MongoDB, MySQL, and SQLite. \\nSkilled in crafting efficient, maintainable code and dedicated to staying updated with\\nindustry trends. Seeking opportunities to apply my Python development skills to innovative\\nprojects.\\nImplemented Named Entity Recognition (NER) to extract quantity, name, and unit of\\ningredients.\\nDeveloped a custom spaCy model trained on tagged data for precise extraction of recipe\\nelements from sentences. \\nUtilized Python, BeautifulSoup and spaCy for data extraction and NER. \\nSpearheaded the implementation of semantic search functionality within OpenSearch to\\nenhance recommendation systems. \\nContributed in the development of a chatbot by leveraging resources from LangChain\\ndocuments.\\nUtilized Python, Opensearch, Langchain, OpenAI and Pandas, Sentence-Transformers,\\n      HuggingFace.Authentication System To Avoid Shoulder Surfing \\nDesigned a secure login system using patterns to protect user credentials from shoulder\\nsurfing attack.\\nImplemented a three-phase authentication process: Registration, Verification, and Login. \\nUtilized Django ORM for efficient data management using SQLite database during user\\nregistration.\\nUtilized Django, MySql, HTML, CSS, JavaScript.Intern, Techchefz (TCZ DIGITAL PVT LTD), Noida, UP Mar 2022 - Oct 2022\\nAssociate, Techchefz (TCZ DIGITAL PVT LTD), Noida, UP Nov 2022 - Dec 2023', metadata={'source': 'Mansukh_CV.pdf', 'page': 0}), Document(page_content='EDUCATION\\nB a c h e l o r  o f  T e c h n o l o g y  i n  C o m p u t e r  S c i e n c e\\nManav Rachna International Institute of Research and Studies A u g  2 0 1 8  -  J u n e  2 0 2 2\\nPERSONAL PROJECTS \\nLangChain Q&A Bot\\nDeveloped an intelligent Question and Answering bot using LangChain. \\nImplemented a system allowing users to upload PDF file and pose questions related to the\\ncontent. \\nUtilized Pinecone Vector Database to store embeddings of the text extracted from the PDF\\nfile. \\nLibraries used : Langchain, Fastapi, Streamlit. \\nSemantic Movie Recommendation System\\nImplemented a movie recommender system using semantic search with Elasticsearch.  \\nUtilized the sbert model to generate embeddings for essential fields, storing them efficiently\\nin the Elasticsearch index. \\nEngineered a responsive system to retrieve relevant responses based on user queries.\\nLibraries used : Elasticsearch, Pandas, Sentence-Transformers, Streamlit.\\nB o o k  S c r a p e\\nEngineered a Flask-based web app for scraping and showcasing book details.\\nIntegrated MongoDB to streamline data management for efficient storage.\\nContributed to a user-friendly platform, showcasing web development skills.\\nLibraries used : BeautifulSoup4, Flask, PyMongo.\\nSKILLS\\nPython\\nPandas\\nNumpy\\nDjango\\nFlaskElasticsearch\\nFastAPI\\nLangchain\\nOpenAI\\nSpacyDocker\\nPostman\\nBeautifulSoup\\nMongoDB\\nMySQLHTML\\nCSS\\nJavaScript\\nACHIEVEMENTS\\n7 weeks online on Programming for everybody (python) | Coursera.\\nLearn My Sql - For Beginners | Coursera.\\n8 weeks on data science course | 4 Achievers.HuggingFace\\n9 month internship as a Python Developer at Techchefz (TCZ DIGITAL PVT LTD).', metadata={'source': 'Mansukh_CV.pdf', 'page': 1})]\n"
     ]
    }
   ],
   "source": [
    "# pdf loader\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "pdf_loader = PyPDFLoader(\"Mansukh_CV.pdf\")\n",
    "docs = pdf_loader.load()\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 200\n",
    ")\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='effective web development. \\nHands-on-experience in database management with MongoDB, MySQL, and SQLite. \\nSkilled in crafting efficient, maintainable code and dedicated to staying updated with\\nindustry trends. Seeking opportunities to apply my Python development skills to innovative\\nprojects.\\nImplemented Named Entity Recognition (NER) to extract quantity, name, and unit of\\ningredients.\\nDeveloped a custom spaCy model trained on tagged data for precise extraction of recipe\\nelements from sentences. \\nUtilized Python, BeautifulSoup and spaCy for data extraction and NER. \\nSpearheaded the implementation of semantic search functionality within OpenSearch to\\nenhance recommendation systems. \\nContributed in the development of a chatbot by leveraging resources from LangChain\\ndocuments.\\nUtilized Python, Opensearch, Langchain, OpenAI and Pandas, Sentence-Transformers,\\n      HuggingFace.Authentication System To Avoid Shoulder Surfing', metadata={'source': 'Mansukh_CV.pdf', 'page': 0})]\n"
     ]
    }
   ],
   "source": [
    "print(documents[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvectorstores\u001b[39;00m \u001b[39mimport\u001b[39;00m Chroma\n\u001b[1;32m----> 3\u001b[0m documents \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39;49mfrom_documents(\n\u001b[0;32m      4\u001b[0m     documents, \n\u001b[0;32m      5\u001b[0m     OpenAIEmbeddings()\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Data Science\\Generative AI\\virtualenv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:778\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[1;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    776\u001b[0m texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m    777\u001b[0m metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m--> 778\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_texts(\n\u001b[0;32m    779\u001b[0m     texts\u001b[39m=\u001b[39;49mtexts,\n\u001b[0;32m    780\u001b[0m     embedding\u001b[39m=\u001b[39;49membedding,\n\u001b[0;32m    781\u001b[0m     metadatas\u001b[39m=\u001b[39;49mmetadatas,\n\u001b[0;32m    782\u001b[0m     ids\u001b[39m=\u001b[39;49mids,\n\u001b[0;32m    783\u001b[0m     collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[0;32m    784\u001b[0m     persist_directory\u001b[39m=\u001b[39;49mpersist_directory,\n\u001b[0;32m    785\u001b[0m     client_settings\u001b[39m=\u001b[39;49mclient_settings,\n\u001b[0;32m    786\u001b[0m     client\u001b[39m=\u001b[39;49mclient,\n\u001b[0;32m    787\u001b[0m     collection_metadata\u001b[39m=\u001b[39;49mcollection_metadata,\n\u001b[0;32m    788\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    789\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Data Science\\Generative AI\\virtualenv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:736\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbatch_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m create_batches\n\u001b[0;32m    730\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m create_batches(\n\u001b[0;32m    731\u001b[0m         api\u001b[39m=\u001b[39mchroma_collection\u001b[39m.\u001b[39m_client,\n\u001b[0;32m    732\u001b[0m         ids\u001b[39m=\u001b[39mids,\n\u001b[0;32m    733\u001b[0m         metadatas\u001b[39m=\u001b[39mmetadatas,\n\u001b[0;32m    734\u001b[0m         documents\u001b[39m=\u001b[39mtexts,\n\u001b[0;32m    735\u001b[0m     ):\n\u001b[1;32m--> 736\u001b[0m         chroma_collection\u001b[39m.\u001b[39;49madd_texts(\n\u001b[0;32m    737\u001b[0m             texts\u001b[39m=\u001b[39;49mbatch[\u001b[39m3\u001b[39;49m] \u001b[39mif\u001b[39;49;00m batch[\u001b[39m3\u001b[39;49m] \u001b[39melse\u001b[39;49;00m [],\n\u001b[0;32m    738\u001b[0m             metadatas\u001b[39m=\u001b[39;49mbatch[\u001b[39m2\u001b[39;49m] \u001b[39mif\u001b[39;49;00m batch[\u001b[39m2\u001b[39;49m] \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    739\u001b[0m             ids\u001b[39m=\u001b[39;49mbatch[\u001b[39m0\u001b[39;49m],\n\u001b[0;32m    740\u001b[0m         )\n\u001b[0;32m    741\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    742\u001b[0m     chroma_collection\u001b[39m.\u001b[39madd_texts(texts\u001b[39m=\u001b[39mtexts, metadatas\u001b[39m=\u001b[39mmetadatas, ids\u001b[39m=\u001b[39mids)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Data Science\\Generative AI\\virtualenv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:275\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m texts \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(texts)\n\u001b[0;32m    274\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 275\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_function\u001b[39m.\u001b[39;49membed_documents(texts)\n\u001b[0;32m    276\u001b[0m \u001b[39mif\u001b[39;00m metadatas:\n\u001b[0;32m    277\u001b[0m     \u001b[39m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     \u001b[39m# did not specify metadata for all texts\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     length_diff \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(texts) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(metadatas)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Data Science\\Generative AI\\virtualenv\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:668\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    666\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    667\u001b[0m engine \u001b[39m=\u001b[39m cast(\u001b[39mstr\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeployment)\n\u001b[1;32m--> 668\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Data Science\\Generative AI\\virtualenv\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:494\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    492\u001b[0m batched_embeddings: List[List[\u001b[39mfloat\u001b[39m]] \u001b[39m=\u001b[39m []\n\u001b[0;32m    493\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[1;32m--> 494\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[0;32m    495\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    496\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtokens[i : i \u001b[39m+\u001b[39;49m _chunk_size],\n\u001b[0;32m    497\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invocation_params,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    499\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    500\u001b[0m         response \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mdict()\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Data Science\\Generative AI\\virtualenv\\Lib\\site-packages\\langchain_community\\embeddings\\openai.py:116\u001b[0m, in \u001b[0;36membed_with_retry\u001b[1;34m(embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Use tenacity to retry the embedding call.\"\"\"\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m is_openai_v1():\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m embeddings\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    117\u001b[0m retry_decorator \u001b[39m=\u001b[39m _create_retry_decorator(embeddings)\n\u001b[0;32m    119\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Data Science\\Generative AI\\virtualenv\\Lib\\site-packages\\openai\\resources\\embeddings.py:113\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    107\u001b[0m         embedding\u001b[39m.\u001b[39membedding \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfrombuffer(  \u001b[39m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    108\u001b[0m             base64\u001b[39m.\u001b[39mb64decode(data), dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m         )\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m    111\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\n\u001b[1;32m--> 113\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[0;32m    114\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m/embeddings\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    115\u001b[0m     body\u001b[39m=\u001b[39;49mmaybe_transform(params, embedding_create_params\u001b[39m.\u001b[39;49mEmbeddingCreateParams),\n\u001b[0;32m    116\u001b[0m     options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[0;32m    117\u001b[0m         extra_headers\u001b[39m=\u001b[39;49mextra_headers,\n\u001b[0;32m    118\u001b[0m         extra_query\u001b[39m=\u001b[39;49mextra_query,\n\u001b[0;32m    119\u001b[0m         extra_body\u001b[39m=\u001b[39;49mextra_body,\n\u001b[0;32m    120\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    121\u001b[0m         post_parser\u001b[39m=\u001b[39;49mparser,\n\u001b[0;32m    122\u001b[0m     ),\n\u001b[0;32m    123\u001b[0m     cast_to\u001b[39m=\u001b[39;49mCreateEmbeddingResponse,\n\u001b[0;32m    124\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Data Science\\Generative AI\\virtualenv\\Lib\\site-packages\\openai\\_base_client.py:1208\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1194\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[0;32m   1195\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1196\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1203\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1204\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m   1205\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[0;32m   1206\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[0;32m   1207\u001b[0m     )\n\u001b[1;32m-> 1208\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Data Science\\Generative AI\\virtualenv\\Lib\\site-packages\\openai\\_base_client.py:897\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    889\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    890\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    895\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    896\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m--> 897\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    898\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    899\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    900\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    901\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    902\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[0;32m    903\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Data Science\\Generative AI\\virtualenv\\Lib\\site-packages\\openai\\_base_client.py:973\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[0;32m    972\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 973\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m    974\u001b[0m         options,\n\u001b[0;32m    975\u001b[0m         cast_to,\n\u001b[0;32m    976\u001b[0m         retries,\n\u001b[0;32m    977\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    978\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    979\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    980\u001b[0m     )\n\u001b[0;32m    982\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Data Science\\Generative AI\\virtualenv\\Lib\\site-packages\\openai\\_base_client.py:1021\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1019\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1021\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m   1022\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m   1023\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m   1024\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m   1025\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m   1026\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m   1027\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Data Science\\Generative AI\\virtualenv\\Lib\\site-packages\\openai\\_base_client.py:973\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_retry(err\u001b[39m.\u001b[39mresponse):\n\u001b[0;32m    972\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 973\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retry_request(\n\u001b[0;32m    974\u001b[0m         options,\n\u001b[0;32m    975\u001b[0m         cast_to,\n\u001b[0;32m    976\u001b[0m         retries,\n\u001b[0;32m    977\u001b[0m         err\u001b[39m.\u001b[39;49mresponse\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    978\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    979\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    980\u001b[0m     )\n\u001b[0;32m    982\u001b[0m \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    983\u001b[0m \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mis_closed:\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Data Science\\Generative AI\\virtualenv\\Lib\\site-packages\\openai\\_base_client.py:1021\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[39m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m \u001b[39m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1019\u001b[0m time\u001b[39m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1021\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m   1022\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m   1023\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m   1024\u001b[0m     remaining_retries\u001b[39m=\u001b[39;49mremaining,\n\u001b[0;32m   1025\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m   1026\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m   1027\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\Data Science\\Generative AI\\virtualenv\\Lib\\site-packages\\openai\\_base_client.py:988\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    985\u001b[0m         err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[0;32m    987\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRe-raising status error\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 988\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_response(\n\u001b[0;32m    991\u001b[0m     cast_to\u001b[39m=\u001b[39mcast_to,\n\u001b[0;32m    992\u001b[0m     options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    995\u001b[0m     stream_cls\u001b[39m=\u001b[39mstream_cls,\n\u001b[0;32m    996\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "documents = Chroma.from_documents(\n",
    "    documents, \n",
    "    OpenAIEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('virtualenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d082fa5c73ca3049439b63ceeeb9011df0b3d34742a5780eff208165c368c14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
