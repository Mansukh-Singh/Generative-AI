{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "pdf_loader = PyPDFLoader(\"Mansukh_CV.pdf\")\n",
    "docs = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 200\n",
    ")\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.ollama import OllamaEmbeddings\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone.vectorstores import PineconeVectorStore\n",
    "import os \n",
    "os.environ['PINECONE_API_KEY'] = os.getenv(\"PINCONE_API_KEY\")\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model = \"mxbai-embed-large\"\n",
    ")\n",
    "doc_search = PineconeVectorStore.from_documents(\n",
    "    documents,\n",
    "    embeddings,\n",
    "    index_name = \"langchain-index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template='''\n",
    "          Answer the following question based on the given {context}\n",
    "          Question : {input}\n",
    "          I need answer in the given format below:\n",
    "          Question : Here will be the question given by the user\n",
    "          Answer: Here will be the answer provided by the model\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.ollama import Ollama\n",
    "llm = Ollama(\n",
    "    model=\"llama2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "chain = create_stuff_documents_chain(\n",
    "    llm,\n",
    "    prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "retriever = doc_search.as_retriever()\n",
    "response = create_retrieval_chain(\n",
    "    retriever,\n",
    "    chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = response.invoke({'input':'What are the projects that have done by the developer?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Question: Can you tell me about the projects you've worked on as a developer?\n",
      "Answer: Sure! As a developer, I have worked on several projects that showcase my skills in web development, data science, and natural language processing.\n",
      "\n",
      "One of the projects I worked on was an engineered system to retrieve relevant responses based on user queries. I used Elasticsearch, Pandas, Sentence-Transformers, and Streamlit to build this system. It allowed me to demonstrate my ability to integrate multiple libraries and tools to create a responsive and efficient system.\n",
      "\n",
      "Another project I worked on was a Flask-based web app for scraping and showcasing book details. I integrated MongoDB to streamline data management and make it more efficient. This project allowed me to demonstrate my skills in web development and database management.\n",
      "\n",
      "In addition, I contributed to a user-friendly platform that showcased my ability to build intuitive and user-friendly interfaces. I used BeautifulSoup4, Flask, PyMongo to build this platform.\n",
      "\n",
      "Some of my other projects include implementing Named Entity Recognition (NER) to extract quantity, name, and unit of ingredients, developing a custom spaCy model trained on tagged data for precise extraction of recipe elements from sentences, spearheading the implementation of semantic search functionality within OpenSearch to enhance recommendation systems, contributing in the development of a chatbot by leveraging resources from LangChain documents, and utilizing Python, Opensearch, Langchain, OpenAI, and Pandas, Sentence-Transformers, HuggingFace to develop an authentication system to avoid shoulder surfing.\n",
      "\n",
      "Overall, my projects demonstrate my ability to work on a wide range of tasks and technologies, from web development and data science to natural language processing and machine learning.\n"
     ]
    }
   ],
   "source": [
    "print(result['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('virtualenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d082fa5c73ca3049439b63ceeeb9011df0b3d34742a5780eff208165c368c14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
