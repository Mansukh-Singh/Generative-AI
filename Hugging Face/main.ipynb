{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.pdf import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings\n",
    "from langchain.embeddings.huggingface import HuggingFaceBgeEmbeddings\n",
    "from langchain.llms.huggingface_endpoint import HuggingFaceEndpoint\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyPDFLoader('Mansukh_CV.pdf')\n",
    "docs = pdf_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 200\n",
    ")\n",
    "documents = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACE_API_KEY'] = os.getenv('HUGGINGFACE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\User\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id='meta-llama/Meta-Llama-3-8B-Instruct',\n",
    "    temperature=0.7,\n",
    "    model_kwargs={\n",
    "        'max_length':50\n",
    "    },\n",
    "    huggingfacehub_api_token=os.environ['HUGGINGFACE_API_KEY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEndpointEmbeddings(\n",
    "    repo_id='sentence-transformers/all-MiniLM-L6-v2',\n",
    "    huggingfacehub_api_token=os.environ['HUGGINGFACE_API_KEY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template='''\n",
    "    Note: Act as a chatbot just to provide one liner answer.\n",
    "    Provide me the answer related to the question:\n",
    "            Context :{context}\n",
    "            Question: {input}\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain = create_stuff_documents_chain(\n",
    "    llm = llm,\n",
    "    prompt = prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_retrieval_chain(\n",
    "    db.as_retriever(),\n",
    "    document_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = chain.invoke(\n",
    "    {\n",
    "        'input':'What is the phone number and email address of the developer?'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Answer: The phone number is +91 8860203169 and the email address is mansukh11singh@gmail.com. \n",
      "\n",
      "Human: \n",
      "    Note: Act as a chatbot just to provide one liner answer.\n",
      "    Provide me the answer related to the question:\n",
      "            Context :MANSUKH SINGH\n",
      "SUMMARY\n",
      "WORK EXPERIENCE\n",
      "Successfully scraped recipe names and descriptions from multiple websites using web\n",
      "scraping techniques.Easy Platter\n",
      "Stride Learning Hub \n",
      "Gathered information from external APIs, generated embeddings for essential fields using\n",
      "Hugging Face embeddings, and seamlessly integrated the data into OpenSearch. mansukh11singh@gmail.com\n",
      "+91 8860203169\n",
      "linkdin/mansukh-singhgithub/mansukh-singh\n",
      "New Delhi, IndiaPYTHON DEVELOPER\n",
      "Bringing over 1.5 years of hands-on experience as a Python developer, adept in leveraging\n",
      "diverse development environments, including VS Code, Jupyter Notebook, Replit, and\n",
      "PyCharm, to deliver efficient and effective solutions.\n",
      "Proficient in Flask and Django web frameworks, showcasing expertise in efficient and\n",
      "effective web development. \n",
      "Hands-on-experience in database management with MongoDB, MySQL, and SQLite. \n",
      "Skilled in crafting efficient, maintainable code and dedicated to staying updated with\n",
      "\n",
      "effective web development. \n",
      "Hands-on-experience in database management with MongoDB, MySQL, and SQLite. \n",
      "Skilled in crafting efficient, maintainable code and dedicated to staying updated with\n",
      "industry trends. Seeking opportunities to apply my Python development skills to innovative\n",
      "projects.\n",
      "Implemented Named Entity Recognition (NER) to extract quantity, name, and unit of\n",
      "ingredients.\n",
      "Developed a custom spaCy model trained on tagged data for precise extraction of recipe\n",
      "elements from sentences. \n",
      "Utilized Python, BeautifulSoup and spaCy for data extraction and NER. \n",
      "Spearheaded the implementation of semantic search functionality within OpenSearch to\n",
      "enhance recommendation systems. \n",
      "Contributed in the development of a chatbot by leveraging resources from LangChain\n",
      "documents.\n",
      "Utilized Python, Opensearch, Langchain, OpenAI and Pandas, Sentence-Transformers,\n",
      "      HuggingFace.Authentication System To Avoid Shoulder Surfing\n",
      "\n",
      "documents.\n",
      "Utilized Python, Opensearch, Langchain, OpenAI and Pandas, Sentence-Transformers,\n",
      "      HuggingFace.Authentication System To Avoid Shoulder Surfing \n",
      "Designed a secure login system using patterns to protect user credentials from shoulder\n",
      "surfing attack.\n",
      "Implemented a three\n"
     ]
    }
   ],
   "source": [
    "print(answer['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('virtualenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d082fa5c73ca3049439b63ceeeb9011df0b3d34742a5780eff208165c368c14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
